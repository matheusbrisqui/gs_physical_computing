## BlackOutCare â€“ Reconhecimento Corporal para SituaÃ§Ãµes de ApagÃ£o

Guilherme Rezende Bezerra RM: 95808 ||
Gustavo Brisqui Martinez RM: 97969 ||
Matheus Brisqui Martinez RM: 97892 ||

## ðŸ§  DescriÃ§Ã£o do Problema

Durante apagÃµes, muitas pessoas enfrentam dificuldades para pedir ajuda ou se locomover com seguranÃ§a, principalmente em hospitais, centros de comando, residÃªncias com idosos ou pessoas com deficiÃªncia. Nessas situaÃ§Ãµes, a falta de iluminaÃ§Ã£o torna os mÃ©todos tradicionais de comunicaÃ§Ã£o (voz, botÃ£o, telefone) menos acessÃ­veis. Por isso, Ã© necessÃ¡rio desenvolver uma alternativa tecnolÃ³gica acessÃ­vel, de fÃ¡cil uso e sem dependÃªncia de hardware externo.

---

## ðŸ’¡ VisÃ£o Geral da SoluÃ§Ã£o

O **BlackOutCare** Ã© um sistema de detecÃ§Ã£o de gestos de emergÃªncia com **MediaPipe Pose**, que utiliza a **webcam em tempo real** para identificar se o usuÃ¡rio levanta o braÃ§o acima do ombro â€” gesto que indica um pedido de ajuda.

Ao detectar esse gesto, o sistema dispara um **som de alerta**, permitindo que o usuÃ¡rio chame atenÃ§Ã£o em ambientes escuros ou em situaÃ§Ãµes crÃ­ticas durante uma falha de energia. A interface exibe o corpo com landmarks desenhados (pontos e conexÃµes) em tempo real, facilitando a visualizaÃ§Ã£o da detecÃ§Ã£o.

Essa soluÃ§Ã£o nÃ£o requer sensores fÃ­sicos como Arduino ou ESP32 â€” funciona apenas com software Python, uma webcam e luz ambiente mÃ­nima.

---

## ðŸ§° Tecnologias Utilizadas

- Python 3.11+
- OpenCV (processamento de vÃ­deo)
- MediaPipe Pose (reconhecimento de pontos do corpo)
- Playsound (reproduÃ§Ã£o de som de alerta)

---

## Link do vÃ­deo

 - https://youtu.be/BEhALLhySb0
---

## CÃ³digo fonte
import cv2
import mediapipe as mp
from playsound import playsound
import threading

mp_pose = mp.solutions.pose
mp_drawing = mp.solutions.drawing_utils

def tocar_alerta():
    playsound('alerta.mp3')

def detectar_pose():
    cap = cv2.VideoCapture(0)

    with mp_pose.Pose(min_detection_confidence=0.7, min_tracking_confidence=0.7) as pose:
        alerta_disparado = False

        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                break

            dark_frame = cv2.convertScaleAbs(frame, alpha=0.6, beta=0)
            rgb = cv2.cvtColor(dark_frame, cv2.COLOR_BGR2RGB)
            result = pose.process(rgb)

            if result.pose_landmarks:
                mp_drawing.draw_landmarks(
                    dark_frame, result.pose_landmarks, mp_pose.POSE_CONNECTIONS
                )

                landmarks = result.pose_landmarks.landmark
                ombro_direito = landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER]
                mao_direita = landmarks[mp_pose.PoseLandmark.RIGHT_WRIST]

                # Verifica se os pontos estÃ£o confiÃ¡veis (visibilidade e valores vÃ¡lidos)
                if (ombro_direito.visibility > 0.5 and mao_direita.visibility > 0.5):
                    if mao_direita.y < ombro_direito.y:
                        if not alerta_disparado:
                            print("ðŸš¨ Gesto de emergÃªncia detectado (braÃ§o levantado)!")
                            threading.Thread(target=tocar_alerta).start()
                            alerta_disparado = True
                    else:
                        alerta_disparado = False

            cv2.imshow('SafeSign - Pose Estimation', dark_frame)
            if cv2.waitKey(10) & 0xFF == 27:
                break

    cap.release()
    cv2.destroyAllWindows()

if __name__ == "__main__":
    detectar_pose()
